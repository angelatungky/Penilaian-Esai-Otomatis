{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10448883,"sourceType":"datasetVersion","datasetId":6467689},{"sourceId":10475641,"sourceType":"datasetVersion","datasetId":6486533},{"sourceId":10477219,"sourceType":"datasetVersion","datasetId":6486932}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n# Load your custom dataset from a CSV file\ndef load_indo_dataset(filename):\n    # Read the CSV file\n    df = pd.read_csv(filename)\n    print(df.head())\n    # Extract columns 'answer', 'response', and 'label'\n    # Normalize the label to [0, 1]\n    data = [\n        (row['answer'], row['response'], row['label'] / 5.0)\n        for _, row in df.iterrows()\n    ]\n\n    return data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:15.228523Z","iopub.execute_input":"2025-01-19T12:44:15.228776Z","iopub.status.idle":"2025-01-19T12:44:15.563472Z","shell.execute_reply.started":"2025-01-19T12:44:15.228754Z","shell.execute_reply":"2025-01-19T12:44:15.562439Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\nfile_path = '/kaggle/input/indo-datanew/indodataset.csv'\ndf = pd.read_csv(file_path)\n\n# Check the first few rows\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:15.564479Z","iopub.execute_input":"2025-01-19T12:44:15.564993Z","iopub.status.idle":"2025-01-19T12:44:15.605596Z","shell.execute_reply.started":"2025-01-19T12:44:15.564958Z","shell.execute_reply":"2025-01-19T12:44:15.604733Z"}},"outputs":[{"name":"stdout","text":"                                              answer  \\\n0  ilmu pengetahuan yang mempelajari gejala alam ...   \n1  ilmu pengetahuan yang mempelajari gejala alam ...   \n2  ilmu pengetahuan yang mempelajari gejala alam ...   \n3  ilmu pengetahuan yang mempelajari gejala alam ...   \n4  ilmu pengetahuan yang mempelajari gejala alam ...   \n\n                                            response  label  \n0  Ilmu yang mempelajari tentang fenomena alam da...    2.5  \n1  ilmu pengetahuan yang mempelajari gejala alam ...    4.0  \n2  pelajaran yang mempelajari tentang suatu perhi...    1.0  \n3  ilmu yang mempelajari tentang bumi, lingkungan...    2.0  \n4  ilmu yang mengajarkan tentang fenomena yang ad...    1.0  \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:15.606611Z","iopub.execute_input":"2025-01-19T12:44:15.606974Z","iopub.status.idle":"2025-01-19T12:44:15.627777Z","shell.execute_reply.started":"2025-01-19T12:44:15.606887Z","shell.execute_reply":"2025-01-19T12:44:15.626651Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1845 entries, 0 to 1844\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   answer    1845 non-null   object \n 1   response  1845 non-null   object \n 2   label     1845 non-null   float64\ndtypes: float64(1), object(2)\nmemory usage: 43.4+ KB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset\nfile_path = '/kaggle/input/indo-datanew/indodataset.csv'\ndf = pd.read_csv(file_path)\n\n# Find rows with missing values\nmissing_values = df[df.isnull().any(axis=1)]\n\n# Display the rows and their indices\nprint(\"Rows with missing values:\")\nprint(missing_values)\n\n# Display the row numbers\nprint(\"\\nIndices of rows with missing values:\")\nprint(missing_values.index.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:15.630023Z","iopub.execute_input":"2025-01-19T12:44:15.630255Z","iopub.status.idle":"2025-01-19T12:44:15.660493Z","shell.execute_reply.started":"2025-01-19T12:44:15.630230Z","shell.execute_reply":"2025-01-19T12:44:15.659526Z"}},"outputs":[{"name":"stdout","text":"Rows with missing values:\nEmpty DataFrame\nColumns: [answer, response, label]\nIndex: []\n\nIndices of rows with missing values:\n[]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Check for missing or infinite values\nprint(df.isnull().sum())  # Ensure no missing values\nprint((df == float('inf')).sum())  # Check for infinite values\nprint((df == float('-inf')).sum())  # Check for negative infinite values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:15.662161Z","iopub.execute_input":"2025-01-19T12:44:15.662515Z","iopub.status.idle":"2025-01-19T12:44:15.671724Z","shell.execute_reply.started":"2025-01-19T12:44:15.662486Z","shell.execute_reply":"2025-01-19T12:44:15.670762Z"}},"outputs":[{"name":"stdout","text":"answer      0\nresponse    0\nlabel       0\ndtype: int64\nanswer      0\nresponse    0\nlabel       0\ndtype: int64\nanswer      0\nresponse    0\nlabel       0\ndtype: int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install transformers sentence-transformers datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:15.672774Z","iopub.execute_input":"2025-01-19T12:44:15.673208Z","iopub.status.idle":"2025-01-19T12:44:20.163703Z","shell.execute_reply.started":"2025-01-19T12:44:15.673169Z","shell.execute_reply":"2025-01-19T12:44:20.162307Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport datetime\nimport time\nimport random\nfrom transformers import BertTokenizer\nfrom sentence_transformers import SentenceTransformer, models\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom scipy.stats import pearsonr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:20.164886Z","iopub.execute_input":"2025-01-19T12:44:20.165274Z","iopub.status.idle":"2025-01-19T12:44:42.440969Z","shell.execute_reply.started":"2025-01-19T12:44:20.165238Z","shell.execute_reply":"2025-01-19T12:44:42.440045Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Split dataset into train, validation, and test\ndef split_dataset(data, valid_percentage, test_percentage):\n    length = len(data)\n    np.random.shuffle(data)\n    train = data[:int(length * (1 - valid_percentage - test_percentage))]\n    valid = data[int(length * (1 - valid_percentage - test_percentage)):int(length * (1 - test_percentage))]\n    test = data[int(length * (1 - test_percentage)):]\n    return train, valid, test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:42.441897Z","iopub.execute_input":"2025-01-19T12:44:42.442587Z","iopub.status.idle":"2025-01-19T12:44:42.447429Z","shell.execute_reply.started":"2025-01-19T12:44:42.442550Z","shell.execute_reply":"2025-01-19T12:44:42.446518Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"data = load_indo_dataset(file_path)\n\n# Split the dataset into train, validation, and test sets\ntrain_data, val_data, test_data = split_dataset(data, valid_percentage=0.1, test_percentage=0.1)\n\n# Check a sample from the loaded data\nprint(f\"Number of samples: {len(data)}\")\nprint(f\"Sample from the dataset: {data[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:42.449312Z","iopub.execute_input":"2025-01-19T12:44:42.449638Z","iopub.status.idle":"2025-01-19T12:44:42.589363Z","shell.execute_reply.started":"2025-01-19T12:44:42.449606Z","shell.execute_reply":"2025-01-19T12:44:42.588347Z"}},"outputs":[{"name":"stdout","text":"                                              answer  \\\n0  ilmu pengetahuan yang mempelajari gejala alam ...   \n1  ilmu pengetahuan yang mempelajari gejala alam ...   \n2  ilmu pengetahuan yang mempelajari gejala alam ...   \n3  ilmu pengetahuan yang mempelajari gejala alam ...   \n4  ilmu pengetahuan yang mempelajari gejala alam ...   \n\n                                            response  label  \n0  Ilmu yang mempelajari tentang fenomena alam da...    2.5  \n1  ilmu pengetahuan yang mempelajari gejala alam ...    4.0  \n2  pelajaran yang mempelajari tentang suatu perhi...    1.0  \n3  ilmu yang mempelajari tentang bumi, lingkungan...    2.0  \n4  ilmu yang mengajarkan tentang fenomena yang ad...    1.0  \nNumber of samples: 1845\nSample from the dataset: ('mengamati (observasi), mengklasifikasi, mengukur, mengajukan pertanyaan, merumuskan hipotesis, merencanakan penelitian, menafsirkan data, Mengkomunikasikan', 'Fakta - Hukum - Model\\nKonsep - Rumus\\nPrinsip - Teori', 0.0)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Save datasets to CSV files\ndef save_splits_to_csv(train_data, val_data, test_data, output_dir):\n    os.makedirs(output_dir, exist_ok=True)\n\n    train_df = pd.DataFrame(train_data, columns=[\"response\", \"answer\", \"label\"])\n    val_df = pd.DataFrame(val_data, columns=[\"response\", \"answer\", \"label\"])\n    test_df = pd.DataFrame(test_data, columns=[\"response\", \"answer\", \"label\"])\n\n    train_df.to_csv(os.path.join(output_dir, \"train_data.csv\"), index=False)\n    val_df.to_csv(os.path.join(output_dir, \"val_data.csv\"), index=False)\n    test_df.to_csv(os.path.join(output_dir, \"test_data.csv\"), index=False)\n\n    print(f\"Data saved to {output_dir} successfully.\")\n\n# Load datasets from CSV files\ndef load_splits_from_csv(output_dir):\n    train_df = pd.read_csv(os.path.join(output_dir, \"train_data.csv\"))\n    val_df = pd.read_csv(os.path.join(output_dir, \"val_data.csv\"))\n    test_df = pd.read_csv(os.path.join(output_dir, \"test_data.csv\"))\n\n    # Convert dataframes back to lists of tuples\n    train_data = list(train_df.itertuples(index=False, name=None))\n    val_data = list(val_df.itertuples(index=False, name=None))\n    test_data = list(test_df.itertuples(index=False, name=None))\n\n    print(f\"Data loaded from {output_dir} successfully.\")\n    return train_data, val_data, test_data\n\n# Save splits to CSV\noutput_directory = \"output_splits\"\nsave_splits_to_csv(train_data, val_data, test_data, output_directory)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:42.590246Z","iopub.execute_input":"2025-01-19T12:44:42.590519Z","iopub.status.idle":"2025-01-19T12:44:42.618555Z","shell.execute_reply.started":"2025-01-19T12:44:42.590497Z","shell.execute_reply":"2025-01-19T12:44:42.617650Z"}},"outputs":[{"name":"stdout","text":"Data saved to output_splits successfully.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Load splits from CSV\ntrain_data, val_data, test_data = load_splits_from_csv(output_directory)\n\n# Check the first few rows to ensure data integrity\nprint(\"Train Data (First 5 Rows):\", train_data[:5])\nprint(\"Validation Data (First 5 Rows):\", val_data[:5])\nprint(\"Test Data (First 5 Rows):\", test_data[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:42.619415Z","iopub.execute_input":"2025-01-19T12:44:42.619670Z","iopub.status.idle":"2025-01-19T12:44:42.637681Z","shell.execute_reply.started":"2025-01-19T12:44:42.619649Z","shell.execute_reply":"2025-01-19T12:44:42.636888Z"}},"outputs":[{"name":"stdout","text":"Data loaded from output_splits successfully.\nTrain Data (First 5 Rows): [('mengamati (observasi), mengklasifikasi, mengukur, mengajukan pertanyaan, merumuskan hipotesis, merencanakan penelitian, menafsirkan data, Mengkomunikasikan', 'Fakta - Hukum - Model\\nKonsep - Rumus\\nPrinsip - Teori', 0.0), ('penanda waktu, kesempatan, durasi, tempo, dan timing.', 'penanda waktu,kesempatan,durasi,tempo dan timing', 1.0), ('Riasan yang digunakan untuk mempertajam atau mempertegas garis wajah tanpa menghilangkan bentuk wajah asli penari.', 'riasan yang digunakan untuk mempertajam atau mempertegas garis wajah tanpa menghilangkan bentuk wajah asli penari', 1.0), ('Nilai moral, yaitu nilai yang berkaitan dengan baik buruknya tokoh.\\nNilai sosial, yaitu nilai yang berkaitan dengan sikap tokoh dalam hubungannya dengan tokoh lain\\nNilai religi, yaitu nilai yang berhubungan dengan hubungan manusia dengan Tuhan.\\nNilai budaya, yaitu nilai yang berkaitan dengan kebiasaan masyarakat saat itu.\\nNilai pendidikan, yaitu nilai yang berkaitan dengan upaya seseorang mencari ilmu pengetahuan.', 'Nilai moral: berperilaku baik/buruk suatu tokoh\\nNilai agama: hubungan tokoh dan Tuhan\\nNilai pendidikan: bangsa yang mengandung cerita bangsawan\\nNilai budaya: kebiasaan perilaku suatu tokoh\\nNilai sosial: perilaku masyarakat', 1.0), ('Orientasi: Pengenalan tokoh-tokoh dalam cerita.\\nPemunculan Konflik: Awal kemunculan konflik dalam suatu cerita.\\nKomplikasi: Peningkatan konflik yang membuat konflik mulai memuncak.\\nKlimaks: Puncak konflik atau masalah paling intens.\\nResolusi: Penyelesaian masalah', 'Abstraksi\\nOrientasi\\nKlimaks\\nResolusi', 0.5)]\nValidation Data (First 5 Rows): [('rasa ingin tahu objektif/jujur berpikir kritis berpikir terbuka sikap penemuan dan kreatif', '1. Jujur 2. Kreatif 3. Memiliki pemikiran terbuka 4. Rasa ingin tahu 5. Dan berpikir kritis', 0.9), ('suatu cara sistematis yang digunakan untuk mengembangkan dan menemukan suatu ilmu pengetahuan.', 'proses untuk memahami fenomena dengan informasi yang sudah ada.', 0.0), ('variabel yang harus dipertahankan tetap selama penelitian sehingga tidak memengaruhi variabel terikat', 'Adalah variabel tetap yang harus dipertahankan selama penelitian agar tidak berubah.', 0.8), ('penghubung antartulang dan keberadaannya memungkinkan tulang-tulang dapat digerakkan', 'pusat gerak', 0.0), ('jawaban sementara dari masalah yang diteliti sehingga kebenarannya harus diuji secara empiris.', 'jawaban sementara yang kebenarannya masih harus diuji oleh fakta empiris.', 0.8)]\nTest Data (First 5 Rows): [('Nilai moral, yaitu nilai yang berkaitan dengan baik buruknya tokoh.\\nNilai sosial, yaitu nilai yang berkaitan dengan sikap tokoh dalam hubungannya dengan tokoh lain\\nNilai religi, yaitu nilai yang berhubungan dengan hubungan manusia dengan Tuhan.\\nNilai budaya, yaitu nilai yang berkaitan dengan kebiasaan masyarakat saat itu.\\nNilai pendidikan, yaitu nilai yang berkaitan dengan upaya seseorang mencari ilmu pengetahuan.', 'Nilai moral\\nNilai Pendidikan\\nNilai Sosial\\nNilai Budaya\\nNilai Religi', 0.5), ('musik pengiring, tata busana, tata rias, properti tari', 'Unsur - unsur yang memungkinkan gerak tari menjadi lebih bermakna dan lebih menarik,serta sesuai dengan isi tarian yang dikehendaki penata tari', 0.1), ('Pengetahuan yang diperoleh dengan menggunakan cara-cara tertentu yang teratur dan terkontrol.', 'melakukan atau membuat sebuah metode dalam penelitian ilmiah.', 0.0), ('tungkai atas dan bawah, telapak kaki, jari-jari kaki.', 'tungkai atas dan bawah, telapak kaki dan jari kaki.', 1.0), ('gerak tari yang menggambarkan suatu hal secara simbolik melalui hal-hal yang tidak realistik (abstrak)', 'gerak tari yang menggambarkan suatu hal secara simbolik melalui hal-hal yg tidak realistis (abstrak)', 1.0)]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Highlighted: Use the IndoBERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:42.638537Z","iopub.execute_input":"2025-01-19T12:44:42.638919Z","iopub.status.idle":"2025-01-19T12:44:43.932812Z","shell.execute_reply.started":"2025-01-19T12:44:42.638857Z","shell.execute_reply":"2025-01-19T12:44:43.931849Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d896030ca92e4529950335cb1e73fd94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b11c53012384ae9b946290530336cb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c28ec0ce1574835833fb29d273927a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e8b969538d5421ca035df7e36f21e4c"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def format_time(elapsed):\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:43.936202Z","iopub.execute_input":"2025-01-19T12:44:43.936455Z","iopub.status.idle":"2025-01-19T12:44:43.940809Z","shell.execute_reply.started":"2025-01-19T12:44:43.936433Z","shell.execute_reply":"2025-01-19T12:44:43.939965Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Correct the CustomDataset __getitem__ method\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, data):\n        self.first_sentences = [pair[0] for pair in data]\n        self.second_sentences = [pair[1] for pair in data]\n        self.labels = [pair[2] for pair in data]\n\n    def __len__(self):\n        return len(self.first_sentences)\n\n    def __getitem__(self, idx):\n        texts = tokenizer(\n            self.first_sentences[idx],\n            self.second_sentences[idx],\n            padding=\"max_length\",\n            max_length=128,\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n        return {\n            'input_ids': texts['input_ids'].squeeze(0),\n            'attention_mask': texts['attention_mask'].squeeze(0),\n        }, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:43.942409Z","iopub.execute_input":"2025-01-19T12:44:43.942728Z","iopub.status.idle":"2025-01-19T12:44:43.957553Z","shell.execute_reply.started":"2025-01-19T12:44:43.942700Z","shell.execute_reply":"2025-01-19T12:44:43.956445Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Create DataLoader\nbatch_size = 8\ntrain_ds = CustomDataset(train_data)\nval_ds = CustomDataset(val_data)\ntest_ds = CustomDataset(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:43.958587Z","iopub.execute_input":"2025-01-19T12:44:43.958899Z","iopub.status.idle":"2025-01-19T12:44:43.970472Z","shell.execute_reply.started":"2025-01-19T12:44:43.958869Z","shell.execute_reply":"2025-01-19T12:44:43.969562Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalidation_dataloader = DataLoader(val_ds, batch_size=batch_size)\ntest_dataloader = DataLoader(test_ds, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:43.971527Z","iopub.execute_input":"2025-01-19T12:44:43.971838Z","iopub.status.idle":"2025-01-19T12:44:43.984691Z","shell.execute_reply.started":"2025-01-19T12:44:43.971795Z","shell.execute_reply":"2025-01-19T12:44:43.983644Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Enhanced Model with IndoBERT\nclass EnhancedBertModel(nn.Module):\n    def __init__(self):\n        super(EnhancedBertModel, self).__init__()\n        # Highlighted: Use IndoBERT as the transformer\n        self.bert = models.Transformer('indobenchmark/indobert-base-p1', max_seq_length=128)\n        self.pooling_layer = models.Pooling(self.bert.get_word_embedding_dimension())\n\n        # Freeze BERT layers\n        for param in self.bert.parameters():\n            param.requires_grad = False\n\n        self.bi_lstm = nn.LSTM(\n            input_size=self.bert.get_word_embedding_dimension(),\n            hidden_size=64,\n            num_layers=1,\n            bidirectional=True,\n            batch_first=True\n        )\n\n        self.fc_dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(256, 1)\n\n    def forward(self, input_data):\n        bert_output = self.bert(input_data)\n        sequence_output = bert_output['token_embeddings']\n\n        lstm_output, _ = self.bi_lstm(sequence_output)\n\n        avg_pool = torch.mean(lstm_output, dim=1)\n        max_pool, _ = torch.max(lstm_output, dim=1)\n\n        pooled_output = torch.cat((avg_pool, max_pool), dim=1)\n\n        output = self.fc_dropout(pooled_output)\n        output = self.fc(output)\n\n        return output.squeeze(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:43.985705Z","iopub.execute_input":"2025-01-19T12:44:43.986021Z","iopub.status.idle":"2025-01-19T12:44:43.995672Z","shell.execute_reply.started":"2025-01-19T12:44:43.985992Z","shell.execute_reply":"2025-01-19T12:44:43.994606Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Check for GPU availability\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:43.996516Z","iopub.execute_input":"2025-01-19T12:44:43.996819Z","iopub.status.idle":"2025-01-19T12:44:44.132364Z","shell.execute_reply.started":"2025-01-19T12:44:43.996796Z","shell.execute_reply":"2025-01-19T12:44:44.131325Z"}},"outputs":[{"name":"stdout","text":"There are 2 GPU(s) available.\nWe will use the GPU: Tesla T4\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Instantiate and move the model to device\nmodel = EnhancedBertModel()\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:44.133407Z","iopub.execute_input":"2025-01-19T12:44:44.133742Z","iopub.status.idle":"2025-01-19T12:44:51.145954Z","shell.execute_reply.started":"2025-01-19T12:44:44.133708Z","shell.execute_reply":"2025-01-19T12:44:51.144757Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3df1fcb5109491f8c59d12a335060e4"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"EnhancedBertModel(\n  (bert): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n  (pooling_layer): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n  (bi_lstm): LSTM(768, 64, batch_first=True, bidirectional=True)\n  (fc_dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=256, out_features=1, bias=True)\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Loss function, optimizer, and scheduler\ncriterion = nn.MSELoss()\nepochs = 8\noptimizer = optim.Adam(model.parameters(), lr=1e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:51.147200Z","iopub.execute_input":"2025-01-19T12:44:51.147500Z","iopub.status.idle":"2025-01-19T12:44:51.153586Z","shell.execute_reply.started":"2025-01-19T12:44:51.147474Z","shell.execute_reply":"2025-01-19T12:44:51.152629Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Training Loop\ndef train_model():\n    training_stats = []\n    total_t0 = time.time()\n\n    for epoch_i in range(epochs):\n        print(f\"\\n======== Epoch {epoch_i + 1} / {epochs} ========\")\n        print(\"Training...\")\n\n        t0 = time.time()\n        total_train_loss = 0\n        model.train()\n\n        for batch in tqdm(train_dataloader):\n            train_data, train_labels = batch\n            train_data['input_ids'] = train_data['input_ids'].to(device)\n            train_data['attention_mask'] = train_data['attention_mask'].to(device)\n            train_labels = train_labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model({\n                'input_ids': train_data['input_ids'],\n                'attention_mask': train_data['attention_mask']\n            })\n            loss = criterion(outputs, train_labels)\n            total_train_loss += loss.item()\n\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        avg_train_loss = total_train_loss / len(train_dataloader)\n        training_time = format_time(time.time() - t0)\n\n        print(f\"  Average training loss: {avg_train_loss:.5f}\")\n        print(f\"  Training epoch took: {training_time}\")\n\n        # Validation\n        print(\"Running Validation...\")\n        t0 = time.time()\n\n        model.eval()\n        total_val_loss = 0\n\n        for batch in tqdm(validation_dataloader):\n            val_data, val_labels = batch\n            val_data['input_ids'] = val_data['input_ids'].to(device)\n            val_data['attention_mask'] = val_data['attention_mask'].to(device)\n            val_labels = val_labels.to(device)\n\n            with torch.no_grad():\n                outputs = model({\n                    'input_ids': val_data['input_ids'],\n                    'attention_mask': val_data['attention_mask']\n                })\n                loss = criterion(outputs, val_labels)\n                total_val_loss += loss.item()\n\n        avg_val_loss = total_val_loss / len(validation_dataloader)\n        validation_time = format_time(time.time() - t0)\n\n        print(f\"  Validation Loss: {avg_val_loss:.5f}\")\n        print(f\"  Validation took: {validation_time}\")\n\n        training_stats.append({\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Validation Loss': avg_val_loss,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        })\n\n    print(\"Training complete!\")\n    print(f\"Total training took {format_time(time.time() - total_t0)}\")\n    return model, training_stats\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:51.154570Z","iopub.execute_input":"2025-01-19T12:44:51.154946Z","iopub.status.idle":"2025-01-19T12:44:51.300053Z","shell.execute_reply.started":"2025-01-19T12:44:51.154892Z","shell.execute_reply":"2025-01-19T12:44:51.298974Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Train the model\nmodel, training_stats = train_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:44:51.301082Z","iopub.execute_input":"2025-01-19T12:44:51.301361Z","iopub.status.idle":"2025-01-19T12:46:39.173059Z","shell.execute_reply.started":"2025-01-19T12:44:51.301339Z","shell.execute_reply":"2025-01-19T12:46:39.172128Z"}},"outputs":[{"name":"stdout","text":"\n======== Epoch 1 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 11/185 [00:01<00:15, 11.10it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 16%|█▌        | 29/185 [00:02<00:09, 15.64it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 37%|███▋      | 69/185 [00:05<00:07, 15.47it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 43%|████▎     | 79/185 [00:05<00:06, 15.39it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 47%|████▋     | 87/185 [00:06<00:06, 16.09it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 54%|█████▎    | 99/185 [00:07<00:05, 16.28it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 55%|█████▍    | 101/185 [00:07<00:05, 16.16it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 84%|████████▍ | 155/185 [00:10<00:01, 16.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 87%|████████▋ | 161/185 [00:10<00:01, 16.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 88%|████████▊ | 163/185 [00:11<00:01, 16.30it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 92%|█████████▏| 171/185 [00:11<00:00, 16.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:12<00:00, 14.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.35319\n  Training epoch took: 0:00:12\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 2/23 [00:00<00:01, 17.17it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 78%|███████▊  | 18/23 [00:01<00:00, 17.27it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 17.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.20221\n  Validation took: 0:00:01\n\n======== Epoch 2 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 4/185 [00:00<00:11, 16.24it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  8%|▊         | 14/185 [00:00<00:10, 16.28it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 15%|█▌        | 28/185 [00:01<00:09, 16.22it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 28%|██▊       | 52/185 [00:03<00:08, 16.45it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 32%|███▏      | 60/185 [00:03<00:07, 16.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 37%|███▋      | 68/185 [00:04<00:07, 16.25it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 43%|████▎     | 80/185 [00:04<00:06, 16.09it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 45%|████▌     | 84/185 [00:05<00:06, 16.16it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 63%|██████▎   | 116/185 [00:07<00:04, 16.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 80%|████████  | 148/185 [00:09<00:02, 16.00it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 92%|█████████▏| 170/185 [00:10<00:00, 15.98it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:11<00:00, 16.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.20063\n  Training epoch took: 0:00:11\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 2/23 [00:00<00:01, 17.29it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 78%|███████▊  | 18/23 [00:01<00:00, 16.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 16.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.15672\n  Validation took: 0:00:01\n\n======== Epoch 3 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/185 [00:00<00:11, 15.71it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  4%|▍         | 8/185 [00:00<00:11, 15.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  9%|▊         | 16/185 [00:01<00:10, 15.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 14%|█▍        | 26/185 [00:01<00:09, 15.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 36%|███▌      | 66/185 [00:04<00:07, 16.07it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 37%|███▋      | 68/185 [00:04<00:07, 15.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 49%|████▊     | 90/185 [00:05<00:05, 16.18it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 56%|█████▌    | 104/185 [00:06<00:04, 16.24it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 59%|█████▉    | 110/185 [00:06<00:04, 15.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 86%|████████▋ | 160/185 [00:10<00:01, 15.89it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 94%|█████████▍| 174/185 [00:10<00:00, 15.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:11<00:00, 15.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.17957\n  Training epoch took: 0:00:12\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 2/23 [00:00<00:01, 17.22it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 78%|███████▊  | 18/23 [00:01<00:00, 16.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 16.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.13044\n  Validation took: 0:00:01\n\n======== Epoch 4 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 14/185 [00:00<00:10, 15.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 15%|█▌        | 28/185 [00:01<00:09, 15.83it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 18%|█▊        | 34/185 [00:02<00:09, 15.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\nBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 24%|██▍       | 44/185 [00:02<00:08, 15.71it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 30%|███       | 56/185 [00:03<00:08, 15.73it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 39%|███▉      | 72/185 [00:04<00:07, 15.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\nBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 43%|████▎     | 80/185 [00:05<00:06, 15.77it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 55%|█████▌    | 102/185 [00:06<00:05, 15.92it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 74%|███████▎  | 136/185 [00:08<00:03, 15.68it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:11<00:00, 15.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.15439\n  Training epoch took: 0:00:12\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 2/23 [00:00<00:01, 17.34it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 78%|███████▊  | 18/23 [00:01<00:00, 16.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 16.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.11334\n  Validation took: 0:00:01\n\n======== Epoch 5 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 8/185 [00:00<00:11, 15.68it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 15%|█▌        | 28/185 [00:01<00:10, 15.39it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 37%|███▋      | 68/185 [00:04<00:07, 15.60it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 42%|████▏     | 78/185 [00:05<00:06, 15.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 55%|█████▌    | 102/185 [00:06<00:05, 15.69it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 61%|██████    | 112/185 [00:07<00:04, 15.36it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 77%|███████▋  | 142/185 [00:09<00:02, 15.34it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 85%|████████▌ | 158/185 [00:10<00:01, 15.33it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 86%|████████▋ | 160/185 [00:10<00:01, 15.23it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 94%|█████████▍| 174/185 [00:11<00:00, 15.27it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 96%|█████████▌| 178/185 [00:11<00:00, 15.31it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:11<00:00, 15.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.14860\n  Training epoch took: 0:00:12\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 2/23 [00:00<00:01, 16.30it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 78%|███████▊  | 18/23 [00:01<00:00, 16.31it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 16.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.10024\n  Validation took: 0:00:01\n\n======== Epoch 6 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/185 [00:00<00:12, 15.19it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  2%|▏         | 4/185 [00:00<00:12, 14.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 21%|██        | 38/185 [00:02<00:09, 15.25it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 23%|██▎       | 42/185 [00:02<00:09, 15.15it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 24%|██▍       | 44/185 [00:02<00:09, 15.04it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 28%|██▊       | 52/185 [00:03<00:08, 15.01it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 68%|██████▊   | 126/185 [00:08<00:03, 15.22it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 69%|██████▉   | 128/185 [00:08<00:03, 15.06it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 70%|███████   | 130/185 [00:08<00:03, 15.01it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 76%|███████▌  | 140/185 [00:09<00:02, 15.07it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 94%|█████████▍| 174/185 [00:11<00:00, 15.03it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:12<00:00, 15.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.13348\n  Training epoch took: 0:00:12\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 2/23 [00:00<00:01, 16.03it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 78%|███████▊  | 18/23 [00:01<00:00, 15.69it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 15.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.09057\n  Validation took: 0:00:01\n\n======== Epoch 7 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":" 10%|▉         | 18/185 [00:01<00:11, 14.98it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 13%|█▎        | 24/185 [00:01<00:10, 14.89it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 16%|█▌        | 30/185 [00:02<00:10, 15.04it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 44%|████▍     | 82/185 [00:05<00:06, 14.83it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 57%|█████▋    | 106/185 [00:07<00:05, 14.73it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 65%|██████▍   | 120/185 [00:08<00:04, 14.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 69%|██████▉   | 128/185 [00:08<00:03, 14.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 80%|████████  | 148/185 [00:09<00:02, 14.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 89%|████████▊ | 164/185 [00:11<00:01, 14.88it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 91%|█████████ | 168/185 [00:11<00:01, 14.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 96%|█████████▌| 178/185 [00:11<00:00, 14.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:12<00:00, 14.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.13154\n  Training epoch took: 0:00:12\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 2/23 [00:00<00:01, 15.77it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 78%|███████▊  | 18/23 [00:01<00:00, 15.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 15.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.08289\n  Validation took: 0:00:01\n\n======== Epoch 8 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 4/185 [00:00<00:12, 14.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  5%|▌         | 10/185 [00:00<00:11, 14.63it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  8%|▊         | 14/185 [00:00<00:11, 14.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  9%|▊         | 16/185 [00:01<00:11, 14.60it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 14%|█▍        | 26/185 [00:01<00:10, 14.79it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 45%|████▌     | 84/185 [00:05<00:06, 14.65it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 46%|████▋     | 86/185 [00:05<00:06, 14.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 82%|████████▏ | 152/185 [00:10<00:02, 14.62it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 91%|█████████ | 168/185 [00:11<00:01, 14.63it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 95%|█████████▌| 176/185 [00:12<00:00, 14.19it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 97%|█████████▋| 180/185 [00:12<00:00, 14.27it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:12<00:00, 14.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.12165\n  Training epoch took: 0:00:13\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  9%|▊         | 2/23 [00:00<00:01, 15.73it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 78%|███████▊  | 18/23 [00:01<00:00, 15.25it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 15.15it/s]","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.07630\n  Validation took: 0:00:02\nTraining complete!\nTotal training took 0:01:48\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# THIS PART OF CODE IS JUST ADDED\n# Unfreeze BERT layers for fine-tuning\nprint(\"\\nUnfreezing BERT layers for fine-tuning...\")\nfor param in model.bert.parameters():\n    param.requires_grad = True\n\n# Reinitialize the optimizer for fine-tuning\noptimizer = optim.Adam(model.parameters(), lr=1e-5)\n\n# Retrain the entire model with unfrozen BERT\nprint(\"\\nFine-tuning the entire model...\")\nmodel, training_stats = train_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:46:39.173842Z","iopub.execute_input":"2025-01-19T12:46:39.174096Z","iopub.status.idle":"2025-01-19T12:52:19.680504Z","shell.execute_reply.started":"2025-01-19T12:46:39.174077Z","shell.execute_reply":"2025-01-19T12:52:19.679455Z"}},"outputs":[{"name":"stdout","text":"\nUnfreezing BERT layers for fine-tuning...\n\nFine-tuning the entire model...\n\n======== Epoch 1 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 1/185 [00:00<00:37,  4.86it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  4%|▍         | 8/185 [00:01<00:38,  4.61it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  7%|▋         | 13/185 [00:02<00:38,  4.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  9%|▉         | 17/185 [00:03<00:37,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 14%|█▍        | 26/185 [00:05<00:35,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 24%|██▍       | 45/185 [00:09<00:31,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 25%|██▌       | 47/185 [00:10<00:30,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 49%|████▉     | 91/185 [00:20<00:21,  4.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 57%|█████▋    | 106/185 [00:23<00:17,  4.39it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 77%|███████▋  | 142/185 [00:31<00:09,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 83%|████████▎ | 153/185 [00:34<00:07,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:41<00:00,  4.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.09396\n  Training epoch took: 0:00:41\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 1/23 [00:00<00:02,  7.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 74%|███████▍  | 17/23 [00:01<00:00, 14.80it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 14.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.03431\n  Validation took: 0:00:02\n\n======== Epoch 2 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 73/185 [00:15<00:24,  4.62it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 42%|████▏     | 78/185 [00:16<00:23,  4.62it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 44%|████▍     | 81/185 [00:17<00:22,  4.60it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 59%|█████▉    | 109/185 [00:23<00:16,  4.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 67%|██████▋   | 124/185 [00:26<00:13,  4.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 68%|██████▊   | 125/185 [00:27<00:13,  4.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 77%|███████▋  | 143/185 [00:31<00:09,  4.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 82%|████████▏ | 151/185 [00:32<00:07,  4.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 89%|████████▉ | 165/185 [00:35<00:04,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 95%|█████████▍| 175/185 [00:38<00:02,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 97%|█████████▋| 180/185 [00:39<00:01,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:40<00:00,  4.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.06140\n  Training epoch took: 0:00:40\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 1/23 [00:00<00:02,  7.64it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 74%|███████▍  | 17/23 [00:01<00:00, 14.75it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 14.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.02784\n  Validation took: 0:00:02\n\n======== Epoch 3 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 10/185 [00:02<00:38,  4.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  9%|▉         | 17/185 [00:03<00:37,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 33%|███▎      | 61/185 [00:13<00:27,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 65%|██████▌   | 121/185 [00:26<00:14,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 71%|███████   | 131/185 [00:29<00:12,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 75%|███████▍  | 138/185 [00:30<00:10,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 76%|███████▌  | 140/185 [00:31<00:10,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 77%|███████▋  | 143/185 [00:31<00:09,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 79%|███████▉  | 147/185 [00:32<00:08,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 88%|████████▊ | 163/185 [00:36<00:04,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 98%|█████████▊| 181/185 [00:40<00:00,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:40<00:00,  4.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.04844\n  Training epoch took: 0:00:41\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 1/23 [00:00<00:02,  7.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 74%|███████▍  | 17/23 [00:01<00:00, 14.85it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 14.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.02342\n  Validation took: 0:00:02\n\n======== Epoch 4 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 24/185 [00:05<00:35,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 36%|███▌      | 67/185 [00:14<00:26,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 47%|████▋     | 87/185 [00:19<00:21,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 54%|█████▍    | 100/185 [00:22<00:18,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 55%|█████▍    | 101/185 [00:22<00:18,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 68%|██████▊   | 125/185 [00:27<00:13,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 69%|██████▊   | 127/185 [00:28<00:12,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 77%|███████▋  | 143/185 [00:31<00:09,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 86%|████████▌ | 159/185 [00:35<00:05,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 94%|█████████▎| 173/185 [00:38<00:02,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 98%|█████████▊| 181/185 [00:40<00:00,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:40<00:00,  4.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.03610\n  Training epoch took: 0:00:41\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 1/23 [00:00<00:02,  7.63it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 74%|███████▍  | 17/23 [00:01<00:00, 14.79it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 14.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.02534\n  Validation took: 0:00:02\n\n======== Epoch 5 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/185 [00:00<?, ?it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n  3%|▎         | 5/185 [00:00<00:36,  4.89it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 16%|█▌        | 30/185 [00:06<00:34,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 25%|██▍       | 46/185 [00:10<00:30,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\nBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 37%|███▋      | 68/185 [00:14<00:26,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 56%|█████▌    | 104/185 [00:23<00:18,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 59%|█████▉    | 110/185 [00:24<00:16,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 81%|████████  | 150/185 [00:33<00:07,  4.48it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 86%|████████▌ | 159/185 [00:35<00:05,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 90%|█████████ | 167/185 [00:37<00:04,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:41<00:00,  4.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.03059\n  Training epoch took: 0:00:41\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 1/23 [00:00<00:02,  7.61it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 74%|███████▍  | 17/23 [00:01<00:00, 14.79it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 14.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.02216\n  Validation took: 0:00:02\n\n======== Epoch 6 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":" 10%|▉         | 18/185 [00:03<00:37,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 17%|█▋        | 31/185 [00:06<00:34,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 34%|███▎      | 62/185 [00:13<00:27,  4.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 34%|███▍      | 63/185 [00:13<00:27,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 49%|████▊     | 90/185 [00:19<00:21,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 52%|█████▏    | 97/185 [00:21<00:19,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 55%|█████▍    | 101/185 [00:22<00:18,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 70%|██████▉   | 129/185 [00:28<00:12,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 72%|███████▏  | 134/185 [00:29<00:11,  4.48it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 81%|████████  | 150/185 [00:33<00:07,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 91%|█████████ | 168/185 [00:37<00:03,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:40<00:00,  4.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.02852\n  Training epoch took: 0:00:41\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 1/23 [00:00<00:02,  7.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 74%|███████▍  | 17/23 [00:01<00:00, 14.76it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 14.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.01968\n  Validation took: 0:00:02\n\n======== Epoch 7 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▍        | 27/185 [00:05<00:35,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 16%|█▌        | 29/185 [00:06<00:34,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 38%|███▊      | 71/185 [00:15<00:25,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 44%|████▍     | 82/185 [00:18<00:22,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 48%|████▊     | 88/185 [00:19<00:21,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 60%|██████    | 111/185 [00:24<00:16,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 63%|██████▎   | 116/185 [00:25<00:15,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 68%|██████▊   | 125/185 [00:27<00:13,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 72%|███████▏  | 134/185 [00:29<00:11,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\nBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 78%|███████▊  | 144/185 [00:31<00:09,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:40<00:00,  4.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.02455\n  Training epoch took: 0:00:41\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 1/23 [00:00<00:02,  7.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 74%|███████▍  | 17/23 [00:01<00:00, 14.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 14.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.02173\n  Validation took: 0:00:02\n\n======== Epoch 8 / 8 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 23/185 [00:04<00:35,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 13%|█▎        | 24/185 [00:05<00:35,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 23%|██▎       | 43/185 [00:09<00:31,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 24%|██▍       | 44/185 [00:09<00:31,  4.46it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 45%|████▌     | 84/185 [00:18<00:22,  4.48it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 66%|██████▌   | 122/185 [00:27<00:14,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 83%|████████▎ | 153/185 [00:33<00:07,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 84%|████████▍ | 155/185 [00:34<00:06,  4.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 84%|████████▍ | 156/185 [00:34<00:06,  4.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 85%|████████▍ | 157/185 [00:34<00:06,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 86%|████████▋ | 160/185 [00:35<00:05,  4.51it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 185/185 [00:41<00:00,  4.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"  Average training loss: 0.02093\n  Training epoch took: 0:00:41\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 1/23 [00:00<00:02,  7.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 74%|███████▍  | 17/23 [00:01<00:00, 14.80it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 14.31it/s]","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 0.02104\n  Validation took: 0:00:02\nTraining complete!\nTotal training took 0:05:40\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Define custom evaluation functions\ndef mean_squared_error(y_true, y_pred):\n    squared_errors = [(true - pred) ** 2 for true, pred in zip(y_true, y_pred)]\n    return sum(squared_errors) / len(squared_errors)\n\ndef mean_absolute_error(y_true, y_pred):\n    absolute_errors = [abs(true - pred) for true, pred in zip(y_true, y_pred)]\n    return sum(absolute_errors) / len(absolute_errors)\n\ndef root_mean_squared_error(y_true, y_pred):\n    mse = mean_squared_error(y_true, y_pred)\n    return mse ** 0.5\n\ndef pearsonr(x, y):\n    mean_x = sum(x) / len(x)\n    mean_y = sum(y) / len(y)\n    numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n    denominator = ((sum((xi - mean_x) ** 2 for xi in x) * sum((yi - mean_y) ** 2 for yi in y)) ** 0.5)\n    return numerator / denominator if denominator != 0 else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:52:19.681505Z","iopub.execute_input":"2025-01-19T12:52:19.681785Z","iopub.status.idle":"2025-01-19T12:52:19.688158Z","shell.execute_reply.started":"2025-01-19T12:52:19.681764Z","shell.execute_reply":"2025-01-19T12:52:19.687112Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Evaluate Model with custom functions\ndef evaluate_model(model, dataloader):\n    model.eval()\n    true_labels = []\n    predicted_scores = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            data, labels = batch\n            data['input_ids'] = data['input_ids'].to(device)\n            data['attention_mask'] = data['attention_mask'].to(device)\n            predictions = model({\n                'input_ids': data['input_ids'],\n                'attention_mask': data['attention_mask']\n            })\n\n            true_labels.extend(labels.cpu().numpy())\n            predicted_scores.extend(predictions.cpu().numpy())\n\n    mse = mean_squared_error(true_labels, predicted_scores)\n    mae = mean_absolute_error(true_labels, predicted_scores)\n    rmse = root_mean_squared_error(true_labels, predicted_scores)\n    pearson_corr = pearsonr(true_labels, predicted_scores)\n\n    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n    print(f\"Pearson Correlation: {pearson_corr:.4f}\")\n\n    return mse, mae, rmse, pearson_corr\n\n# Evaluate on validation set\nevaluate_model(model, validation_dataloader)\n\n# Optional: Evaluate on the test set if available\ntest_ds = CustomDataset(test_data)\ntest_dataloader = DataLoader(test_ds, batch_size=batch_size)\nprint(\"this is the evaluation on the test set:\")\nevaluate_model(model, test_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:52:19.689278Z","iopub.execute_input":"2025-01-19T12:52:19.689582Z","iopub.status.idle":"2025-01-19T12:52:22.760431Z","shell.execute_reply.started":"2025-01-19T12:52:19.689550Z","shell.execute_reply":"2025-01-19T12:52:22.759697Z"}},"outputs":[{"name":"stderr","text":"Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\nBe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","output_type":"stream"},{"name":"stdout","text":"Mean Squared Error (MSE): 0.0210\nMean Absolute Error (MAE): 0.1058\nRoot Mean Squared Error (RMSE): 0.1450\nPearson Correlation: 0.9230\nthis is the evaluation on the test set:\n","output_type":"stream"},{"name":"stderr","text":"Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","output_type":"stream"},{"name":"stdout","text":"Mean Squared Error (MSE): 0.0278\nMean Absolute Error (MAE): 0.1119\nRoot Mean Squared Error (RMSE): 0.1668\nPearson Correlation: 0.9012\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(0.02781942536563016,\n 0.1118861418318104,\n 0.16679156263321643,\n 0.9011529553446912)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# Save the trained model to a .pt file\nmodel_save_path = \"/kaggle/working/indobert_similarity_model.pt\"\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"Model saved to {model_save_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:52:22.761266Z","iopub.execute_input":"2025-01-19T12:52:22.761508Z","iopub.status.idle":"2025-01-19T12:52:23.552749Z","shell.execute_reply.started":"2025-01-19T12:52:22.761487Z","shell.execute_reply":"2025-01-19T12:52:23.551904Z"}},"outputs":[{"name":"stdout","text":"Model saved to /kaggle/working/indobert_similarity_model.pt\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Reinitialize the model architecture\nmodel = EnhancedBertModel()\nmodel.to(device)\n\n# Load the model state dictionary\nmodel.load_state_dict(torch.load(model_save_path))\nprint(\"Model loaded successfully!\")\n\n# Set the model to evaluation mode if testing\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:52:23.553621Z","iopub.execute_input":"2025-01-19T12:52:23.554109Z","iopub.status.idle":"2025-01-19T12:52:25.147974Z","shell.execute_reply.started":"2025-01-19T12:52:23.554078Z","shell.execute_reply":"2025-01-19T12:52:25.146566Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-27-a5f5a58a1944>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_save_path))\n","output_type":"stream"},{"name":"stdout","text":"Model loaded successfully!\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"EnhancedBertModel(\n  (bert): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n  (pooling_layer): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n  (bi_lstm): LSTM(768, 64, batch_first=True, bidirectional=True)\n  (fc_dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=256, out_features=1, bias=True)\n)"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"def evaluate_and_save_results(model, dataloader, csv_filename, original_data):\n    model.eval()\n    results = []  # To store all prediction results\n    index = 0  # Track the original dataset index\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader):\n            data, labels = batch\n            data['input_ids'] = data['input_ids'].to(device)\n            data['attention_mask'] = data['attention_mask'].to(device)\n            predictions = model({\n                'input_ids': data['input_ids'],\n                'attention_mask': data['attention_mask']\n            }).cpu().numpy()\n\n            batch_size = len(labels)\n            for i in range(batch_size):\n                # Get original sentences (response, answer)\n                response, answer, true_label = original_data[index]\n                index += 1  # Move to the next pair\n\n                results.append({\n                    'Response': response,\n                    'Answer': answer,\n                    'True Label': true_label,\n                    'Predicted Score': predictions[i]\n                })\n\n    # Save results to CSV\n    df = pd.DataFrame(results)\n    df.to_csv(csv_filename, index=False)\n    print(f\"Results saved to {csv_filename}\")\n    \n    return df\n\n# Save validation results\nvalidation_results_csv = \"/kaggle/working/validation_results.csv\"\ndf_validation = evaluate_and_save_results(model, validation_dataloader, validation_results_csv, val_data)\n\n# Load test data for testing\ntest_ds = CustomDataset(test_data)\ntest_dataloader = DataLoader(test_ds, batch_size=batch_size)\n\n# Save test results\ntest_results_csv = \"/kaggle/working/test_results.csv\"\ndf_test = evaluate_and_save_results(model, test_dataloader, test_results_csv, test_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:52:25.149536Z","iopub.execute_input":"2025-01-19T12:52:25.149871Z","iopub.status.idle":"2025-01-19T12:52:28.312700Z","shell.execute_reply.started":"2025-01-19T12:52:25.149843Z","shell.execute_reply":"2025-01-19T12:52:28.311683Z"}},"outputs":[{"name":"stderr","text":"  9%|▊         | 2/23 [00:00<00:01, 10.88it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n 78%|███████▊  | 18/23 [00:01<00:00, 14.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 23/23 [00:01<00:00, 14.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Results saved to /kaggle/working/validation_results.csv\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 10/24 [00:00<00:00, 15.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n100%|██████████| 24/24 [00:01<00:00, 15.59it/s]","output_type":"stream"},{"name":"stdout","text":"Results saved to /kaggle/working/test_results.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"def test_single_data_point(model, tokenizer, sentence1, sentence2):\n    # Prepare input using the tokenizer\n    encoded_input = tokenizer(\n        sentence1,\n        sentence2,\n        padding=\"max_length\",\n        max_length=128,\n        truncation=True,\n        return_tensors=\"pt\"\n    ).to(device)\n\n    # Set the model to evaluation mode\n    model.eval()\n\n    with torch.no_grad():\n        # Perform inference\n        predicted_score = model({\n            'input_ids': encoded_input['input_ids'],\n            'attention_mask': encoded_input['attention_mask']\n        })\n\n    # Since the model output is normalized to [0, 1], rescale it to [0, 5]\n    predicted_score_rescaled = predicted_score.item() * 5.0\n\n    print(f\"Sentence 1: {sentence1}\")\n    print(f\"Sentence 2: {sentence2}\")\n    print(f\"Predicted Similarity Score: {predicted_score_rescaled:.4f}\")\n\n    return predicted_score_rescaled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:52:28.313555Z","iopub.execute_input":"2025-01-19T12:52:28.313876Z","iopub.status.idle":"2025-01-19T12:52:28.319122Z","shell.execute_reply.started":"2025-01-19T12:52:28.313844Z","shell.execute_reply":"2025-01-19T12:52:28.318166Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Example test data point from the test set\ntest_sentence1 = test_data[0][0]  # Replace with the first sentence from your test data\ntest_sentence2 = test_data[0][1]  # Replace with the second sentence from your test data\ntrue_score = test_data[0][2] * 5.0  # Rescale the true label to the [0, 5] range for comparison\n\nprint(f\"True Similarity Score: {true_score:.4f}\")\npredicted_score = test_single_data_point(model, tokenizer, test_sentence1, test_sentence2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:52:28.320192Z","iopub.execute_input":"2025-01-19T12:52:28.320498Z","iopub.status.idle":"2025-01-19T12:52:28.350844Z","shell.execute_reply.started":"2025-01-19T12:52:28.320468Z","shell.execute_reply":"2025-01-19T12:52:28.350015Z"}},"outputs":[{"name":"stdout","text":"True Similarity Score: 2.5000\nSentence 1: Nilai moral, yaitu nilai yang berkaitan dengan baik buruknya tokoh.\nNilai sosial, yaitu nilai yang berkaitan dengan sikap tokoh dalam hubungannya dengan tokoh lain\nNilai religi, yaitu nilai yang berhubungan dengan hubungan manusia dengan Tuhan.\nNilai budaya, yaitu nilai yang berkaitan dengan kebiasaan masyarakat saat itu.\nNilai pendidikan, yaitu nilai yang berkaitan dengan upaya seseorang mencari ilmu pengetahuan.\nSentence 2: Nilai moral\nNilai Pendidikan\nNilai Sosial\nNilai Budaya\nNilai Religi\nPredicted Similarity Score: 2.3664\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Example test data point from the test set\ntest_sentence1 = test_data[5][0]  # Replace with the first sentence from your test data\ntest_sentence2 = test_data[5][1]  # Replace with the second sentence from your test data\ntrue_score = test_data[5][2] * 5.0  # Rescale the true label to the [0, 5] range for comparison\n\nprint(f\"True Similarity Score: {true_score:.4f}\")\npredicted_score = test_single_data_point(model, tokenizer, test_sentence1, test_sentence2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:52:28.351720Z","iopub.execute_input":"2025-01-19T12:52:28.352048Z","iopub.status.idle":"2025-01-19T12:52:28.369799Z","shell.execute_reply.started":"2025-01-19T12:52:28.352024Z","shell.execute_reply":"2025-01-19T12:52:28.368833Z"}},"outputs":[{"name":"stdout","text":"True Similarity Score: 5.0000\nSentence 1: tema tokoh penokohan alur latar sudut pandang amanat\nSentence 2: Tema\nTokoh\nPenokohan\nAlur\nLatar\nSudut pandang\nAmanat\nPredicted Similarity Score: 4.7203\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"import csv\n\n# Evaluate model on the unseen dataset and save results to CSV\ndef evaluate_and_save_results(model, dataloader, output_csv_path):\n    model.eval()\n    true_labels = []\n    predicted_scores = []\n    responses = []\n    answers = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            data, labels = batch\n            data['input_ids'] = data['input_ids'].to(device)\n            data['attention_mask'] = data['attention_mask'].to(device)\n            predictions = model({\n                'input_ids': data['input_ids'],\n                'attention_mask': data['attention_mask']\n            })\n\n            true_labels.extend(labels.cpu().numpy())\n            predicted_scores.extend(predictions.cpu().numpy())\n            responses.extend(data['input_ids'].cpu().numpy())  # Add the actual `response`\n            answers.extend(data['attention_mask'].cpu().numpy())  # Add the `answer`\n\n    # Calculate metrics\n    mse = mean_squared_error(true_labels, predicted_scores)\n    mae = mean_absolute_error(true_labels, predicted_scores)\n    rmse = root_mean_squared_error(true_labels, predicted_scores)\n    pearson_corr = pearsonr(true_labels, predicted_scores)\n\n    print(f\"\\nEvaluation on Unseen Dataset:\")\n    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n    print(f\"Pearson Correlation: {pearson_corr:.4f}\")\n\n    # Save results to CSV\n    results = {\n        'answer': [tokenizer.decode(answers[i]) for i in range(len(answers))],\n        'response': [tokenizer.decode(responses[i]) for i in range(len(responses))],\n        'label': true_labels,\n        'predicted_label': predicted_scores,\n    }\n\n    df_results = pd.DataFrame(results)\n    df_results.to_csv(output_csv_path, index=False)\n    print(f\"Results saved to {output_csv_path}\")\n\n# Load unseen dataset and create DataLoader\nunseen_data = load_indo_dataset(\"/kaggle/input/testi-data/test-BuIng.csv\")\nunseen_dataset = CustomDataset(unseen_data)\nunseen_dataloader = DataLoader(unseen_dataset, batch_size=batch_size)\n\n# Evaluate and save to CSV\noutput_csv_path = \"/kaggle/working/unseen_dataset_results.csv\"\nevaluate_and_save_results(model, unseen_dataloader, output_csv_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T12:52:28.370851Z","iopub.execute_input":"2025-01-19T12:52:28.371216Z","iopub.status.idle":"2025-01-19T12:52:28.625301Z","shell.execute_reply.started":"2025-01-19T12:52:28.371184Z","shell.execute_reply":"2025-01-19T12:52:28.624532Z"}},"outputs":[{"name":"stdout","text":"                                              answer  \\\n0  animasi adalah sebuah proses merekam dan memai...   \n1  animasi adalah menghidupkan, yaitu usaha untuk...   \n2  animasi adalah sebuah proses merekam dan memai...   \n3  animasi adalah sebuah proses merekam dan memai...   \n4  animasi adalah menghidupkan, yaitu usaha untuk...   \n\n                                            response  label  \n0  animasi komputer adalah pembuatan atau pemrose...    2.5  \n1  animasi komputer merupakan sebuah bentuk seni ...    4.5  \n2  animasi yang dibuat pada saat sekarang dan dib...    2.5  \n3  sebuah animasi dimana animasi ini sebuah perge...    4.0  \n4    proses menciptakan gerakan menggunakan komputer    5.0  \n","output_type":"stream"},{"name":"stderr","text":"Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","output_type":"stream"},{"name":"stdout","text":"\nEvaluation on Unseen Dataset:\nMean Squared Error (MSE): 0.2420\nMean Absolute Error (MAE): 0.4348\nRoot Mean Squared Error (RMSE): 0.4920\nPearson Correlation: 0.0140\nResults saved to /kaggle/working/unseen_dataset_results.csv\n","output_type":"stream"}],"execution_count":32}]}